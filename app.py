# import io
# from pathlib import Path

# import numpy as np
# import streamlit as st
# import tensorflow as tf
# from PIL import Image

# # Model/training constants taken from the original notebook.
# IMAGE_SIZE = 224
# LABELS = ['NORMAL', 'TUBERCULOSIS', 'PNEUMONIA', 'COVID19']
# MODEL_PATH = Path(__file__).resolve().parent / 'final_model.keras'


# @st.cache_resource(show_spinner=True)
# def load_model():
#     if not MODEL_PATH.exists():
#         raise FileNotFoundError(
#             f"Could not find trained model at {MODEL_PATH}. "
#             "Make sure final_model.keras is placed beside app.py."
#         )
#     return tf.keras.models.load_model(MODEL_PATH)


# def preprocess_image(image: Image.Image) -> np.ndarray:
#     """Resize + normalize image exactly as done during training."""
#     image = image.convert('RGB').resize((IMAGE_SIZE, IMAGE_SIZE))
#     array = np.asarray(image, dtype='float32')
#     max_val = array.max()
#     if max_val > 0:
#         array /= max_val
#     array = np.expand_dims(array, axis=0)
#     return array


# def predict(model: tf.keras.Model, image_array: np.ndarray):
#     probs = model.predict(image_array, verbose=0)[0]
#     top_idx = int(np.argmax(probs))
#     return LABELS[top_idx], probs


# def render_sidebar():
#     st.sidebar.title('Model Facts')
#     st.sidebar.markdown(
#         '- Backbone: MobileNetV2 (ImageNet weights frozen)\n'
#         '- Input size: 224√ó224 RGB\n'
#         '- Classes: NORMAL, TUBERCULOSIS, PNEUMONIA, COVID19\n'
#         '- Augmentation: brightness & contrast jitter\n'
#         '- Training split: 80% train / 20% val\n'
#         '- Metric: accuracy ‚âà 0.95 on validation'
#     )
#     st.sidebar.info(
#         'Need help? Drag & drop a chest X-ray as JPG/PNG. '
#         'The model will output the most likely diagnosis.'
#     )


# def main():
#     st.set_page_config(page_title='Chest X-ray Diagnosis', layout='wide')
#     st.title('Chest X-ray Classification (MobileNetV2)')
#     st.caption('Model weights loaded from `final_model.keras` generated by the notebook.')

#     render_sidebar()

#     uploader = st.file_uploader(
#         'Upload a chest X-ray (JPG/PNG)', type=['jpg', 'jpeg', 'png']
#     )

#     if uploader is None:
#         st.info('Upload an image to start the diagnosis.')
#         return

#     bytes_data = uploader.read()
#     if not bytes_data:
#         st.warning('The uploaded file is empty.')
#         return

#     try:
#         image = Image.open(io.BytesIO(bytes_data))
#     except Exception as exc:
#         st.error(f'Failed to open image: {exc}')
#         return

#     st.image(image, caption='Uploaded X-ray', use_column_width=True)

#     with st.spinner('Running inference...'):
#         model = load_model()
#         processed = preprocess_image(image)
#         prediction, probabilities = predict(model, processed)

#     st.success(f'Prediction: **{prediction}**')

#     probability_table = {
#         label: float(prob) for label, prob in zip(LABELS, probabilities)
#     }
#     st.subheader('Class probabilities')
#     st.bar_chart(probability_table)


# if __name__ == '__main__':
#     main()

#--------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------

import io
import json
import os
from datetime import datetime
from pathlib import Path
import uuid

import numpy as np
import pandas as pd
import streamlit as st
import tensorflow as tf
from PIL import Image

# ----------------------------
# Config / Constants
# ----------------------------
IMAGE_SIZE = 224
LABELS = ['NORMAL', 'TUBERCULOSIS', 'PNEUMONIA', 'COVID19']
MODEL_PATH = Path(__file__).resolve().parent / 'final_model.keras'

DATA_DIR = Path("data")
IMAGES_DIR = DATA_DIR / "history_images"
HISTORY_FILE = DATA_DIR / "history.json"

# Operational settings
MAX_HISTORY_ITEMS = 1000  # rotate / limit if desired
MAX_UPLOAD_MB = 12  # reject extremely large uploads
CONFIDENCE_THRESHOLD = 0.60  # below this, mark as low confidence

# Ensure folders exist
DATA_DIR.mkdir(exist_ok=True)
IMAGES_DIR.mkdir(parents=True, exist_ok=True)

# Suppress verbose TF logs
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'


# ===============================
# History Helpers
# ===============================
def load_history():
    if HISTORY_FILE.exists():
        try:
            with open(HISTORY_FILE, "r") as f:
                return json.load(f)
        except Exception:
            # corrupted history -> reset
            return []
    return []


def save_history(record):
    history = load_history()
    history.append(record)
    # Optionally enforce a max length
    if len(history) > MAX_HISTORY_ITEMS:
        # remove oldest entries (and their image files)
        to_remove = len(history) - MAX_HISTORY_ITEMS
        for _ in range(to_remove):
            old = history.pop(0)
            _remove_image_file(old.get("image_path"))
    with open(HISTORY_FILE, "w") as f:
        json.dump(history, f, indent=2)


def delete_history_item(index):
    history = load_history()
    if 0 <= index < len(history):
        item = history.pop(index)
        _remove_image_file(item.get("image_path"))
        with open(HISTORY_FILE, "w") as f:
            json.dump(history, f, indent=2)


def clear_all_history():
    history = load_history()
    for item in history:
        _remove_image_file(item.get("image_path"))
    if HISTORY_FILE.exists():
        HISTORY_FILE.unlink()


def _remove_image_file(path_str):
    if not path_str:
        return
    try:
        p = Path(path_str)
        if p.exists():
            p.unlink()
    except Exception:
        # ignore deletion errors
        pass


# ===============================
# Model Loading (cached)
# ===============================
@st.cache_resource(show_spinner=True)
def load_model():
    if not MODEL_PATH.exists():
        raise FileNotFoundError(
            f"Could not find trained model at {MODEL_PATH}. Place final_model.keras beside app.py."
        )
    try:
        # load with compile=False to avoid shape/optimizer warnings if unnecessary
        model = tf.keras.models.load_model(MODEL_PATH, compile=False)
        return model
    except Exception as e:
        raise RuntimeError(f"Failed to load model: {e}")


# ===============================
# Preprocessing
# ===============================
def preprocess_image(pil_image: Image.Image) -> np.ndarray:
    """
    Convert PIL image to model-ready array:
    - convert to RGB
    - resize to IMAGE_SIZE
    - convert to float32
    - apply mobilenet_v2 preprocess_input (scales to [-1,1])
    - expand dims for batch
    """
    image = pil_image.convert("RGB").resize((IMAGE_SIZE, IMAGE_SIZE))
    array = np.asarray(image, dtype="float32")
    # MobileNetV2 expects preprocess_input
    array = tf.keras.applications.mobilenet_v2.preprocess_input(array)  # scales to [-1,1]
    return np.expand_dims(array, axis=0)


# ===============================
# Predict
# ===============================
def predict(model: tf.keras.Model, image_array: np.ndarray):
    probs = model.predict(image_array, verbose=0)[0]
    # safety: ensure probs is a numpy array
    probs = np.asarray(probs, dtype="float32")
    top_idx = int(np.argmax(probs))
    top_label = LABELS[top_idx]
    top_prob = float(probs[top_idx])
    probs_dict = {label: float(p) for label, p in zip(LABELS, probs)}
    return top_label, top_prob, probs_dict


# ===============================
# UI Helpers
# ===============================
def save_uploaded_file_to_disk(uploaded_file: st.runtime.uploaded_file_manager.UploadedFile):
    # ensure unique filename
    ext = Path(uploaded_file.name).suffix.lower()
    unique_name = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex}{ext}"
    out_path = IMAGES_DIR / unique_name
    with open(out_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return str(out_path)


# ------------------------------
# Sidebar (with disclaimer)
# ------------------------------
def render_sidebar():
    st.sidebar.title("üìò Model Details")
    st.sidebar.markdown(
        """
        **Backbone:** MobileNetV2  
        **Input:** 224√ó224 RGB (automatically resized)  
        **Classes:** NORMAL, TUBERCULOSIS, PNEUMONIA, COVID19  
        **Processing:** MobileNetV2 `preprocess_input` (scales pixels to [-1,1])  
        """
    )
    st.sidebar.info("üí° Upload a chest X-ray image (JPG/PNG). The app returns model predictions and stores lightweight history.")

    # Medical / legal disclaimer
    st.sidebar.markdown("---")
    st.sidebar.markdown(
        """
        ### ‚ö†Ô∏è Important Disclaimer
        This tool is **research / educational only**.  
        It is **not a medical device**, **not clinically validated**, and **not a substitute** for professional medical advice, diagnosis, or treatment.  
        Always consult a licensed healthcare professional for medical concerns.
        """
    )


# ===============================
# Main App
# ===============================
def main():
    st.set_page_config(page_title="Chest X-ray Diagnosis", layout="wide")
    st.markdown(
        """
        <h1 style='text-align:center; margin-bottom:0;'> MedXNet-AI Multi-Disease Classification System ü©∫
</h1>
        <p style='text-align:center; color:gray; margin-top:0;'>Research / educational prototype ‚Äî not for clinical use.</p>
        """,
        unsafe_allow_html=True,
    )

    render_sidebar()

    # Tabs
    tabs = st.tabs(["üîç Diagnose", "üìú History", "üìà Stats"])

    # ---------- Diagnose Tab ----------
    with tabs[0]:
        st.write("---")
        st.subheader("Upload X-ray Image")

        uploader = st.file_uploader(
            "üì§ Upload a chest X-ray image (JPG / PNG)",
            type=['jpg', 'jpeg', 'png'],
            help=f"Max file size: {MAX_UPLOAD_MB} MB"
        )

        if uploader is None:
            st.info("Please upload an image to run the model.")
        else:
            # Basic file size check
            uploader.seek(0, io.SEEK_END)
            file_size_mb = uploader.tell() / (1024 * 1024)
            uploader.seek(0)
            if file_size_mb > MAX_UPLOAD_MB:
                st.error(f"File too large ({file_size_mb:.2f} MB). Maximum allowed is {MAX_UPLOAD_MB} MB.")
            else:
                try:
                    image = Image.open(io.BytesIO(uploader.read()))
                except Exception as exc:
                    st.error(f"‚ùå Unable to open uploaded file as an image: {exc}")
                    return

                st.markdown("### üñº Uploaded X-ray")
                st.image(image, use_column_width=True)

                # Run model prediction
                try:
                    model = load_model()
                except Exception as exc:
                    st.error(f"Model load error: {exc}")
                    return

                with st.spinner("üîç Running model inference..."):
                    processed = preprocess_image(image)
                    prediction_label, top_prob, probabilities = predict(model, processed)

                # Result card
                st.markdown(
                    f"""
                    <div style="
                        padding:18px;
                        border-radius:10px;
                        background:#f6f9ff;
                        border:1px solid #e1e7ff;
                        margin-top:12px;
                    ">
                        <h2 style="margin:0;">üßæ Prediction Result</h2>
                        <p style="font-size:20px; margin-top:8px;">
                            <b>Disease Detected:</b> <span style="color:#0b57d0;">{prediction_label}</span>
                        </p>
                        <p style="margin:0;">
                            <b>Confidence:</b> {top_prob:.3f}
                        </p>
                    </div>
                    """,
                    unsafe_allow_html=True,
                )

                # Low confidence warning
                if top_prob < CONFIDENCE_THRESHOLD:
                    st.warning(
                        f"Low confidence prediction (top probability {top_prob:.3f} < threshold {CONFIDENCE_THRESHOLD}). "
                        "Interpret with caution."
                    )

                # Probabilities table + chart
                prob_df = pd.DataFrame.from_dict(probabilities, orient="index", columns=["probability"])
                st.markdown("### üìä Class Probabilities")
                st.dataframe(prob_df.style.format("{:.4f}"))
                st.bar_chart(prob_df)

                # Save history entry (image file + metadata)
                try:
                    # Rewind uploader and save buffer to disk
                    uploader.seek(0)
                    image_path = save_uploaded_file_to_disk(uploader)
                    save_history({
                        "filename": uploader.name,
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "prediction": prediction_label,
                        "top_probability": float(top_prob),
                        "probabilities": probabilities,
                        "image_path": image_path
                    })
                    st.success("‚úÖ Prediction saved to history.")
                except Exception as exc:
                    st.error(f"Failed to save history: {exc}")

    # ---------- History Tab ----------
    with tabs[1]:
        st.markdown("## üìú Upload History")
        # Initialize session flags
        if 'delete_index' not in st.session_state:
            st.session_state['delete_index'] = None
        if 'clear_all_clicked' not in st.session_state:
            st.session_state['clear_all_clicked'] = False

        # Delete single item callback
        def on_delete_item(idx):
            st.session_state['delete_index'] = idx

        def on_clear_all():
            st.session_state['clear_all_clicked'] = True

        # Handle deletion actions
        if st.session_state.get('delete_index') is not None:
            try:
                delete_history_item(st.session_state['delete_index'])
                st.success("History entry deleted.")
            except Exception as exc:
                st.error(f"Failed to delete entry: {exc}")
            st.session_state['delete_index'] = None
            st.rerun()

        if st.session_state.get('clear_all_clicked', False):
            try:
                clear_all_history()
                st.success("All history cleared.")
            except Exception as exc:
                st.error(f"Failed to clear history: {exc}")
            st.session_state['clear_all_clicked'] = False
            st.rerun()

        history = load_history()
        if not history:
            st.info("No history recorded yet.")
        else:
            for i, item in enumerate(history):
                with st.container():
                    col1, col2, col3 = st.columns([1, 3, 1])
                    # Thumbnail
                    with col1:
                        try:
                            img_path = item.get("image_path")
                            if img_path and Path(img_path).exists():
                                st.image(str(img_path), caption=item.get("filename"), width=150)
                            else:
                                st.write("Image unavailable")
                        except Exception:
                            st.write("Image unavailable")

                    # Details
                    with col2:
                        st.write(f"**üïí Timestamp:** {item.get('timestamp')}")
                        st.markdown(f"**üîç Prediction:** **{item.get('prediction')}**")
                        st.write(f"**Top Probability:** {item.get('top_probability', 0):.4f}")
                        st.write("#### Probabilities")
                        for label, prob in item.get("probabilities", {}).items():
                            st.write(f"- **{label}:** {prob:.4f}")

                    # Delete button
                    with col3:
                        st.button(
                            "üóëÔ∏è Delete Entry",
                            key=f"delete_item_{i}",
                            on_click=on_delete_item,
                            args=(i,)
                        )

            st.markdown("---")
            st.warning("‚ö†Ô∏è Danger Zone: Delete ALL history records below.")
            st.button(
                "üö® Delete All History Permanently",
                key="delete_all",
                on_click=on_clear_all
            )

    # ---------- Stats Tab ----------
    with tabs[2]:
        st.markdown("## üìà Most Common Diagnoses")
        history = load_history()
        if not history:
            st.info("Not enough data to generate stats.")
        else:
            counts = {}
            for item in history:
                pred = item.get("prediction", "UNKNOWN")
                counts[pred] = counts.get(pred, 0) + 1

            counts_df = pd.DataFrame.from_dict(counts, orient="index", columns=["count"]).sort_values("count", ascending=False)
            st.bar_chart(counts_df)

            st.markdown("### Most recent entries")
            recent = pd.DataFrame(history[-10:][::-1])  # show last 10 most recent
            # Only show a subset of fields
            if not recent.empty:
                recent_view = recent[["timestamp", "filename", "prediction", "top_probability"]]
                st.dataframe(recent_view)

# Entrypoint
if __name__ == "__main__":
    main()
